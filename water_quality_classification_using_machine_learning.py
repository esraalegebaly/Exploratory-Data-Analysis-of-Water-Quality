# -*- coding: utf-8 -*-
"""Water Quality Classification Using Machine Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YMYZJE_43JkrJoSgmVt0lnGSnzzLwUiw
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import accuracy_score,classification_report,ConfusionMatrixDisplay,precision_score,confusion_matrix
import plotly.express as px
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV,RepeatedStratifiedKFold,cross_val_score
import missingno as msno
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import GradientBoostingClassifier

df = pd.read_csv("water_potability.csv")
df.head()

df.describe()

df.info()

df["ph"] = df["ph"].fillna(value=df["ph"].mean())
df["Sulfate"] = df["Sulfate"].fillna(value=df["Sulfate"].mean())
df["Trihalomethanes"] = df["Trihalomethanes"].fillna(value=df["Trihalomethanes"].mean())

df.info()

import matplotlib.pyplot as plt

# Calculate the counts for each category
potability_counts = df['Potability'].value_counts()
labels = ['Not Potable', 'Potable']

# Define colors and explode for a nicer look
colors = ['#ff6f61', '#6baed6']
explode = (0.1, 0)  # Slightly explode the first slice

# Plot the pie chart
plt.figure(figsize=(8, 6))
plt.pie(potability_counts, labels=labels, autopct='%1.2f%%',
        startangle=140, colors=colors, explode=explode,
        shadow=True, textprops={'fontsize': 12})

# Add title and show plot
plt.title("Potability Distribution", fontsize=16)
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Create the clustermap with the 'Blues' colormap
sns.clustermap(
    df.corr(),
    cmap="Blues",  # Blue gradient colormap
    dendrogram_ratio=(0.1, 0.2),
    annot=True,
    fmt=".2f",
    linewidths=0.8,
    figsize=(10, 12),
    cbar_pos=(0.02, 0.8, 0.03, 0.18),  # Adjust the color bar position
    center=0  # Center the colormap at 0 for better distinction
)

# Show the plot
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Split data into potable and non-potable water samples
potability_zero = df.query("Potability == 0")
potable = df.query("Potability == 1")

# Create a 3x3 grid of KDE plots
plt.figure(figsize=(15, 15))
for ax, col in enumerate(df.columns[:9]):
    plt.subplot(3, 3, ax + 1)
    plt.title(f'Distribution of {col}', fontsize=14)

    # KDE plots with improved aesthetics
    sns.kdeplot(
        x=potability_zero[col], label="Non Potable", fill=True,
        color='#FF6F61', alpha=0.6, linewidth=2
    )
    sns.kdeplot(
        x=potable[col], label="Potable", fill=True,
        color='#6BAED6', alpha=0.6, linewidth=2
    )

    plt.legend(loc='best', fontsize=12)
    plt.xlabel("")  # Remove x-axis labels for cleaner look

plt.tight_layout()
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Scatterplot with jitter to prevent overlapping
plt.figure(figsize=(8, 6))
sns.scatterplot(
    x="ph", y="Potability", data=df,
    alpha=0.6, hue="Potability", palette=["#FF6F61", "#6BAED6"], s=80
)
plt.yticks([0, 1], ["Non Potable", "Potable"])
plt.title("pH vs Potability", fontsize=16)
plt.xlabel("pH", fontsize=12)
plt.ylabel("Potability", fontsize=12)
plt.show()

X = df.drop("Potability",axis=1)
y= df["Potability"]

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=13)

scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.fit_transform(X_test)

models =[
    ("Decision Tree Classifier", DecisionTreeClassifier(max_depth=3)),
    ("Random Forest", RandomForestClassifier())
]

finalResults = []

cmList = []

for name, model in models:
    model.fit(X_train_scaled,y_train)
    model_result = model.predict(X_test_scaled)
    score = precision_score(y_test,model_result)
    cm = confusion_matrix(y_test, model_result)

    finalResults.append((name,score))
    cmList.append((name,cm))
finalResults

import matplotlib.pyplot as plt
import seaborn as sns

# Loop through the list of confusion matrices (or any other matrices)
for name, matrix in cmList:
    plt.figure(figsize=(8, 6))  # Set figure size for readability
    sns.heatmap(
        matrix, annot=True, linewidths=0.7, fmt=".1f", cmap="YlGnBu",
        cbar=True, square=True
    )
    plt.title(name, fontsize=14)
    plt.show()

model_params = {
    "Random Forest" :
    {
        "model": RandomForestClassifier(),
        "params":
        {
            "n_estimators":[10,50,100,200,500],
            "max_features":["auto","sqrt","log2"],
            "max_depth":list(range(1,15,3))
        }
    }
}
model_params

cv = RepeatedStratifiedKFold(n_splits=5,n_repeats=2)
scores=[]
for model_name,params in model_params.items():
    rs = RandomizedSearchCV(params["model"],params["params"],cv=cv,n_iter=10)
    rs.fit(X,y)
    scores.append([model_name,dict(rs.best_params_),rs.best_score_])
scores

import matplotlib.pyplot as plt
import seaborn as sns

# Using a clustermap for hierarchical clustering
sns.clustermap(
    cm,
    annot=True,
    fmt='g',
    cmap='Blues',
    linewidths=0.5,
    figsize=(8, 6),
    cbar=True,
    square=True
)
plt.title("Confusion Matrix - Random Forest", fontsize=16)
plt.show()

import matplotlib.pyplot as plt
import numpy as np

plt.figure(figsize=(8, 6))
plt.imshow(cm, interpolation='nearest', cmap='Blues')  # Using imshow for custom display
plt.title("Confusion Matrix - Random Forest", fontsize=16)
plt.colorbar()  # Add color bar for reference
tick_marks = np.arange(len(np.unique(cm)))  # Assuming cm is a 2D array of shape (n_classes, n_classes)
plt.xticks(tick_marks, np.unique(cm), fontsize=12)
plt.yticks(tick_marks, np.unique(cm), fontsize=12)
plt.xlabel("Predicted Label", fontsize=14)
plt.ylabel("True Label", fontsize=14)

# Annotate each cell with the numeric value
thresh = cm.max() / 2.  # Threshold for coloring text
for i, j in np.ndindex(cm.shape):
    plt.text(j, i, cm[i, j],
             horizontalalignment="center",
             color="white" if cm[i, j] > thresh else "black")

plt.show()

plt.figure(figsize=(8, 6))
sns.heatmap(
    cm,
    annot=False,  # Disable default annotations
    cmap='Blues',
    linewidths=0.5,
    cbar=True,
    square=True
)

# Manually add annotations
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        plt.text(j + 0.5, i + 0.5, cm[i, j],
                 ha='center', va='center',
                 color='white' if cm[i, j] > cm.max() / 2 else 'black',
                 fontsize=12)

plt.title("Confusion Matrix - Random Forest", fontsize=16)
plt.xlabel("Predicted Label", fontsize=14)
plt.ylabel("True Label", fontsize=14)
plt.xticks(ticks=np.arange(len(cm)), labels=np.unique(cm), fontsize=12)
plt.yticks(ticks=np.arange(len(cm)), labels=np.unique(cm), fontsize=12)
plt.show()

